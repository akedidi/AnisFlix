//
//  CustomVideoPlayer.swift
//  anisflix
//
//  Created by AI Assistant on 25/11/2025.
//

import SwiftUI
import AVKit
import Combine
#if canImport(GoogleCast)
import GoogleCast
#endif

struct CustomVideoPlayer: View {
    let url: URL
    let title: String
    let subtitles: [Subtitle]
    @Binding var isPresented: Bool
    @Binding var isFullscreen: Bool
    let showFullscreenButton: Bool
    let isLive: Bool
    
    // Progress tracking
    let mediaId: Int?
    let season: Int?
    let episode: Int?
    
    @ObservedObject var playerVM: PlayerViewModel
    @StateObject private var castManager = CastManager.shared
    @State private var showControls = true
    @State private var showSubtitlesMenu = false
    @State private var selectedSubtitle: Subtitle?
    @State private var subtitleOffset: Double = 0
    @State private var castReloadDebounceTask: Task<Void, Never>?
    
    init(url: URL, title: String, subtitles: [Subtitle] = [], isPresented: Binding<Bool>, isFullscreen: Binding<Bool>, showFullscreenButton: Bool = true, isLive: Bool = false, mediaId: Int? = nil, season: Int? = nil, episode: Int? = nil, playerVM: PlayerViewModel) {
        self.url = url
        self.title = title
        self.subtitles = subtitles
        self._isPresented = isPresented
        self._isFullscreen = isFullscreen
        self.showFullscreenButton = showFullscreenButton
        self.isLive = isLive
        self.mediaId = mediaId
        self.season = season
        self.episode = episode
        self.playerVM = playerVM
    }
    
    var body: some View {
        ZStack {
            Color.black.ignoresSafeArea()
            
            // Video Player
            if castManager.isConnected {
                // Show Cast Placeholder
                VStack(spacing: 20) {
                    Image(systemName: "tv")
                        .font(.system(size: 80))
                        .foregroundColor(.gray)
                    Text("Casting to \(castManager.deviceName ?? "Chromecast")")
                        .font(.title2)
                        .foregroundColor(.white)
                }
            } else {
                VideoPlayerView(player: playerVM.player, playerVM: playerVM)
                    .ignoresSafeArea()
                    .onTapGesture {
                        withAnimation {
                            showControls.toggle()
                        }
                    }
            }
            
            // Subtitles Overlay
            if !castManager.isConnected, let sub = selectedSubtitle, let text = playerVM.currentSubtitleText {
                VStack {
                    Spacer()
                    Text(text)
                        .font(.callout)
                        .fontWeight(.semibold)
                        .foregroundColor(.white)
                        .padding(8)
                        .background(Color.black.opacity(0.6))
                        .cornerRadius(8)
                        .padding(.bottom, 60)
                }
                .transition(.opacity)
            }
            
            // Controls Overlay
            if showControls {
                VStack {
                    // Top Bar
                    HStack {
                        // Close button removed as per user request
                        
                        Text(title)
                            .foregroundColor(.white)
                            .font(.headline)
                            .lineLimit(1)
                        
                        Spacer()
                        
                        // AirPlay Button (Top Right)
                        AirPlayView()
                            .frame(width: 44, height: 44)
                    }
                    .padding()
                    .background(
                        LinearGradient(colors: [.black.opacity(0.8), .clear], startPoint: .top, endPoint: .bottom)
                    )
                    
                    Spacer()
                    
                    // Center Play/Pause
                    if playerVM.isBuffering {
                        ProgressView()
                            .tint(.white)
                            .scaleEffect(1.5)
                    } else {
                        Button {
                            if castManager.isConnected {
                                if castManager.mediaStatus?.playerState == .paused || castManager.mediaStatus?.playerState == .idle {
                                    castManager.play()
                                } else {
                                    castManager.pause()
                                }
                            } else {
                                playerVM.togglePlayPause()
                            }
                        } label: {
                            Image(systemName: (castManager.isConnected ? (castManager.mediaStatus?.playerState == .playing || castManager.mediaStatus?.playerState == .buffering) : playerVM.isPlaying) ? "pause.fill" : "play.fill")
                                .font(.system(size: 50))
                                .foregroundColor(.white)
                        }
                    }
                    
                    Spacer()
                    
                    // Bottom Bar
                    VStack(spacing: 12) {
                        // Progress Bar
                        // Custom Progress Bar with Tap-to-Seek
                        CustomProgressBar(
                            value: $playerVM.currentTime,
                            total: playerVM.duration
                        ) { editing in
                            playerVM.isSeeking = editing
                            if !editing {
                                if castManager.isConnected {
                                    castManager.seek(to: playerVM.currentTime)
                                } else {
                                    playerVM.seek(to: playerVM.currentTime)
                                }
                            }
                        }
                        .padding(.horizontal, 4)
                        
                        HStack {
                            Text(formatTime(playerVM.currentTime))
                                .font(.caption)
                                .foregroundColor(.white)
                            
                            Spacer()
                            
                            // Subtitles Button
                            if !subtitles.isEmpty {
                                Button {
                                    showSubtitlesMenu = true
                                } label: {
                                    Image(systemName: "captions.bubble")
                                        .foregroundColor(selectedSubtitle != nil ? AppTheme.primaryRed : .white)
                                        .padding(8)
                                }
                            }
                            
                            // Chromecast Button (Bottom Right)
                            CastButton()
                                .frame(width: 44, height: 44)
                            
                            // PiP Button
                            Button {
                                playerVM.togglePiP()
                            } label: {
                                Image(systemName: "pip.enter")
                                    .foregroundColor(.white)
                                    .padding(8)
                            }
                            
                            // Fullscreen Button
                            if showFullscreenButton {
                                Button {
                                    playerVM.isSwitchingModes = true
                                    withAnimation {
                                        isFullscreen.toggle()
                                    }
                                } label: {
                                    Image(systemName: isFullscreen ? "arrow.down.right.and.arrow.up.left" : "arrow.up.left.and.arrow.down.right")
                                        .foregroundColor(.white)
                                        .padding(8)
                                }
                            }
                            
                            Text(formatTime(playerVM.duration))
                                .font(.caption)
                                .foregroundColor(.white)
                        }
                    }
                    .padding()
                    .background(
                        LinearGradient(colors: [.clear, .black.opacity(0.8)], startPoint: .top, endPoint: .bottom)
                    )
                }
            }
        }
        .onAppear {
            // Check if we are already playing this URL (fullscreen transition)
            let isAlreadyPlaying = playerVM.currentUrl == url
            
            if castManager.isConnected {
                // If connected, check if we need to switch media on Cast
                if castManager.currentMediaUrl != url {
                    print("ðŸ“º Switching Cast media to: \(title)")
                    castManager.loadMedia(url: url, title: title, posterUrl: nil, subtitles: subtitles, activeSubtitleUrl: selectedSubtitle?.url, startTime: playerVM.currentTime, isLive: isLive, subtitleOffset: subtitleOffset)
                }
            } else {
                playerVM.setup(url: url)
            }
            
            // Auto-resume from saved progress ONLY if not already playing
            if !isAlreadyPlaying, let mid = mediaId {
                let progress = WatchProgressManager.shared.getProgress(mediaId: mid, season: season, episode: episode)
                if progress > 0 && progress < 0.95 { // Don't resume if almost finished
                    if let savedTime = WatchProgressManager.shared.getSavedTime(mediaId: mid, season: season, episode: episode) {
                        print("â© Auto-resuming from \(Int(savedTime))s (progress: \(Int(progress * 100))%)")
                        
                        // Seek after a short delay to ensure player is ready
                        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                            playerVM.seek(to: savedTime)
                        }
                    }
                }
            }
        }
        .onDisappear {
            playerVM.cleanup()
        }
        .sheet(isPresented: $showSubtitlesMenu) {
            SubtitleSelectionView(subtitles: subtitles, selectedSubtitle: $selectedSubtitle, subtitleOffset: $subtitleOffset)
                .presentationDetents([.medium])
        }
        .onChange(of: selectedSubtitle?.id) { _ in
            if castManager.isConnected {
                // Reload media to apply subtitle selection (and offset if any)
                // Note: setActiveTrack doesn't support offset change easily if we use proxy.
                // We might need to reload if offset changed too.
                // For now, let's assume setActiveTrack is enough if offset didn't change,
                // BUT our proxy URL includes offset. So if we just switch track, it might use old offset?
                // Actually, tracks are loaded with a specific URL. If we change offset, we need new URLs.
                // So changing subtitle might need reload if we want to ensure offset is applied?
                // But here we just change selection.
                // Let's just reload to be safe and consistent.
                castManager.loadMedia(url: url, title: title, posterUrl: nil, subtitles: subtitles, activeSubtitleUrl: selectedSubtitle?.url, startTime: castManager.getApproximateStreamPosition(), isLive: isLive, subtitleOffset: subtitleOffset)
            } else {
                if let sub = selectedSubtitle, let url = URL(string: sub.url) {
                    playerVM.loadSubtitles(url: url)
                } else {
                    playerVM.clearSubtitles()
                }
            }
        }
        .onChange(of: subtitleOffset) { newOffset in
            print("â±ï¸ Subtitle offset changed: \(newOffset)s")
            playerVM.subtitleOffset = newOffset
            
            if castManager.isConnected {
                // Debounce the reload to avoid spamming the Chromecast while adjusting
                // Cancel previous request
                // Cancel previous request
                
                // We use a Task for debounce in SwiftUI view since we can't easily use performSelector on struct
                // But actually, let's use a State holding a Task
                castReloadDebounceTask?.cancel()
                castReloadDebounceTask = Task {
                    try? await Task.sleep(nanoseconds: 1_500_000_000) // 1.5 seconds
                    if !Task.isCancelled {
                        await MainActor.run {
                            print("ðŸ“º Reloading Cast media with new subtitle offset (debounced)...")
                            castManager.loadMedia(url: url, title: title, posterUrl: nil, subtitles: subtitles, activeSubtitleUrl: selectedSubtitle?.url, startTime: castManager.getApproximateStreamPosition(), isLive: isLive, subtitleOffset: newOffset)
                        }
                    }
                }
            }
        }
        .onChange(of: playerVM.currentTime) { time in
            // Save progress periodically (e.g., every 5 seconds is handled by the throttle or check)
            // But here we can just call save.
            if let mid = mediaId, Int(time) % 5 == 0 {
                WatchProgressManager.shared.saveProgress(
                    mediaId: mid,
                    season: season,
                    episode: episode,
                    currentTime: time,
                    duration: playerVM.duration
                )
            }
        }
        .onChange(of: isPresented) { presented in
            if !presented, let mid = mediaId {
                WatchProgressManager.shared.saveProgress(
                    mediaId: mid,
                    season: season,
                    episode: episode,
                    currentTime: playerVM.currentTime,
                    duration: playerVM.duration
                )
            }
        }
        .onChange(of: url) { newUrl in
            if castManager.isConnected {
                print("ðŸ“º URL changed while casting. Loading new media...")
                castManager.loadMedia(url: newUrl, title: title, posterUrl: nil, subtitles: subtitles, activeSubtitleUrl: selectedSubtitle?.url, startTime: 0, isLive: isLive)
            } else {
                playerVM.setup(url: newUrl)
            }
        }
        .onChange(of: castManager.isConnected) { connected in
            if connected {
                print("ðŸ“º Cast connected! Switching to Cast mode.")
                playerVM.player.pause()
                castManager.loadMedia(url: url, title: title, posterUrl: nil, subtitles: subtitles, activeSubtitleUrl: selectedSubtitle?.url, startTime: playerVM.currentTime, isLive: isLive)
            } else {
                print("ðŸ“± Cast disconnected! Switching back to local player.")
                playerVM.setup(url: url)
                playerVM.seek(to: playerVM.currentTime) // Ideally we should get time from Cast
            }
        }
        .onReceive(Timer.publish(every: 1, on: .main, in: .common).autoconnect()) { _ in
            if castManager.isConnected {
                let time = castManager.getApproximateStreamPosition()
                if !playerVM.isSeeking {
                    playerVM.currentTime = time
                }
                
                if let duration = castManager.mediaStatus?.mediaInformation?.streamDuration, duration > 0 {
                    playerVM.duration = duration
                }
            }
        }

    }
    
    func formatTime(_ seconds: Double) -> String {
        guard !seconds.isNaN && !seconds.isInfinite else { return "00:00" }
        let totalSeconds = Int(seconds)
        let h = totalSeconds / 3600
        let m = (totalSeconds % 3600) / 60
        let s = totalSeconds % 60
        
        if h > 0 {
            return String(format: "%d:%02d:%02d", h, m, s)
        } else {
            return String(format: "%02d:%02d", m, s)
        }
    }
}

// MARK: - Subtitle Selection View

struct SubtitleSelectionView: View {
    let subtitles: [Subtitle]
    @Binding var selectedSubtitle: Subtitle?
    @Binding var subtitleOffset: Double
    @Environment(\.dismiss) var dismiss
    
    var body: some View {
        NavigationView {
            List {
                Section(header: Text("Synchronisation")) {
                    HStack {
                        Text("DÃ©calage")
                        Spacer()
                        Text(String(format: "%.1f s", subtitleOffset))
                            .foregroundColor(.gray)
                    }
                    
                    HStack {
                        Button {
                            subtitleOffset -= 0.5
                        } label: {
                            Image(systemName: "minus.circle.fill")
                                .font(.title2)
                        }
                        .buttonStyle(.borderless)
                        
                        Slider(value: $subtitleOffset, in: -10...10, step: 0.5)
                        
                        Button {
                            subtitleOffset += 0.5
                        } label: {
                            Image(systemName: "plus.circle.fill")
                                .font(.title2)
                        }
                        .buttonStyle(.borderless)
                    }
                }
                
                Section(header: Text("Sous-titres")) {
                    Button {
                        selectedSubtitle = nil
                        dismiss()
                    } label: {
                        HStack {
                            Text("DÃ©sactivÃ©")
                            Spacer()
                            if selectedSubtitle == nil {
                                Image(systemName: "checkmark")
                                    .foregroundColor(AppTheme.primaryRed)
                            }
                        }
                    }
                    .foregroundColor(.primary)
                    
                    ForEach(subtitles, id: \.id) { sub in
                        Button {
                            selectedSubtitle = sub
                            dismiss()
                        } label: {
                            HStack {
                                Text(sub.flag)
                                Text(sub.label)
                                Spacer()
                                if selectedSubtitle?.id == sub.id {
                                    Image(systemName: "checkmark")
                                        .foregroundColor(AppTheme.primaryRed)
                                }
                            }
                        }
                        .foregroundColor(.primary)
                    }
                }
            }
            .navigationTitle("Sous-titres")
            .navigationBarTitleDisplayMode(.inline)
            .toolbar {
                ToolbarItem(placement: .navigationBarTrailing) {
                    Button("Fermer") { dismiss() }
                }
            }
        }
    }
}

// MARK: - Player ViewModel

// MARK: - Player ViewModel

extension Notification.Name {
    static let stopPlayback = Notification.Name("stopPlayback")
}

class PlayerViewModel: NSObject, ObservableObject {
    @Published var player = AVPlayer()
    @Published var isPlaying = false
    @Published var isBuffering = false
    @Published var currentTime: Double = 0
    @Published var duration: Double = 1
    @Published var currentSubtitleText: String?
    @Published var subtitleOffset: Double = 0
    
    var isSeeking = false
    private var timeObserver: Any?
    private var subtitleParser: SubtitleParser?
    private var pipController: AVPictureInPictureController?
    private weak var playerLayer: AVPlayerLayer?
    private var observedItem: AVPlayerItem? // Track the item we're observing
    private(set) var currentUrl: URL? // Track current URL to prevent restart
    var isSwitchingModes = false // Track fullscreen transition
    
    override init() {
        super.init()
        
        // Configure player for background playback
        player.audiovisualBackgroundPlaybackPolicy = .continuesIfPossible
        player.preventsDisplaySleepDuringVideoPlayback = true
        
        // Configure Audio Session immediately
        do {
            try AVAudioSession.sharedInstance().setCategory(.playback, mode: .moviePlayback, options: [.allowAirPlay, .allowBluetooth])
            try AVAudioSession.sharedInstance().setActive(true)
            print("âœ… Audio session configured for background playback")
        } catch {
            print("âŒ Failed to configure audio session: \(error)")
        }
        
        // Listen for stop playback notification
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleStopPlayback(_:)),
            name: .stopPlayback,
            object: nil
        )
    }
    
    deinit {
        NotificationCenter.default.removeObserver(self)
    }
    
    @objc private func handleStopPlayback(_ notification: Notification) {
        // If the notification comes from another player (not self), pause
        if let sender = notification.object as? PlayerViewModel, sender !== self {
            if isPlaying {
                print("â¸ï¸ Pausing playback because another player started")
                player.pause()
                isPlaying = false
            }
        }
    }
    
    func setup(url: URL) {
        // Notify others to stop
        NotificationCenter.default.post(name: .stopPlayback, object: self)
        
        // If same URL, just ensure playing and return
        if url == currentUrl {
            if !isPlaying {
                player.play()
                isPlaying = true
            }
            return
        }
        
        currentUrl = url
        let item = AVPlayerItem(url: url)
        player.replaceCurrentItem(with: item)
        player.play()
        isPlaying = true
        
        // Observe duration
        observedItem = item
        item.addObserver(self, forKeyPath: "duration", options: [.new, .initial], context: nil)
        
        // Observe time
        timeObserver = player.addPeriodicTimeObserver(forInterval: CMTime(seconds: 0.5, preferredTimescale: 600), queue: .main) { [weak self] time in
            guard let self = self, !self.isSeeking else { return }
            self.currentTime = time.seconds
            self.updateSubtitle()
        }
        
        // setupPiP will be called separately with the layer
    }
    
    func setupPiPWithLayer(_ layer: AVPlayerLayer) {
        print("ðŸŽ¬ setupPiPWithLayer called")
        self.playerLayer = layer
        
        // Audio session is already configured in init()
        
        // Setup PiP if supported
        print("ðŸ” Checking PiP support...")
        if AVPictureInPictureController.isPictureInPictureSupported() {
            print("âœ… PiP is supported on this device")
            do {
                pipController = try AVPictureInPictureController(playerLayer: layer)
                pipController?.canStartPictureInPictureAutomaticallyFromInline = true
                print("âœ… PiP controller created successfully")
                print("   - isPictureInPicturePossible: \(pipController?.isPictureInPicturePossible ?? false)")
            } catch {
                print("âŒ Failed to create PiP controller: \(error)")
            }
        } else {
            print("âš ï¸ PiP not supported on this device")
        }
    }
    
    
    func cleanup() {
        // Don't cleanup if we are just switching modes (e.g. fullscreen)
        if isSwitchingModes {
            isSwitchingModes = false
            return
        }
        
        currentUrl = nil
        player.pause()
        if let observer = timeObserver {
            player.removeTimeObserver(observer)
            timeObserver = nil
        }
        // Only remove observer if we actually added one
        if let item = observedItem {
            item.removeObserver(self, forKeyPath: "duration")
            observedItem = nil
        }
    }
    
    func reset() {
        cleanup()
        currentUrl = nil
        currentTime = 0
        duration = 1
        isPlaying = false
        isBuffering = false
        currentSubtitleText = nil
        player.replaceCurrentItem(with: nil)
    }
    
    func togglePlayPause() {
        if isPlaying {
            player.pause()
        } else {
            player.play()
        }
        isPlaying.toggle()
    }
    
    func seek(to time: Double) {
        player.seek(to: CMTime(seconds: time, preferredTimescale: 600))
    }
    
    func loadSubtitles(url: URL) {
        Task {
            do {
                let (data, _) = try await URLSession.shared.data(from: url)
                if let content = String(data: data, encoding: .utf8) {
                    self.subtitleParser = SubtitleParser(content: content)
                }
            } catch {
                print("Failed to load subtitles: \(error)")
            }
        }
    }
    
    func clearSubtitles() {
        subtitleParser = nil
        currentSubtitleText = nil
    }
    
    private func updateSubtitle() {
        guard let parser = subtitleParser else { return }
        // Apply offset: if offset is +1s, it means subtitle should appear 1s later.
        // So we should ask parser for text at (currentTime - offset).
        // Example: Subtitle at 10s. Offset +2s. Should appear at 12s.
        // At 12s, currentTime=12. 12-2 = 10. Parser finds subtitle. Correct.
        currentSubtitleText = parser.text(for: currentTime - subtitleOffset)
    }
    
    func togglePiP() {
        guard let pip = pipController else {
            print("âš ï¸ PiP controller not available")
            return
        }
        if pip.isPictureInPictureActive {
            print("ðŸ”½ Stopping PiP")
            pip.stopPictureInPicture()
        } else {
            print("ðŸ”¼ Starting PiP")
            pip.startPictureInPicture()
        }
    }
    
    
    override func observeValue(forKeyPath keyPath: String?, of object: Any?, change: [NSKeyValueChangeKey : Any]?, context: UnsafeMutableRawPointer?) {
        if keyPath == "duration", let duration = player.currentItem?.duration.seconds, !duration.isNaN {
            DispatchQueue.main.async {
                self.duration = duration
            }
        }
    }
}

// MARK: - Simple Subtitle Parser (SRT/VTT)

class SubtitleParser {
    struct Entry {
        let startTime: Double
        let endTime: Double
        let text: String
    }
    
    private var entries: [Entry] = []
    
    init(content: String) {
        // Basic VTT/SRT parsing logic
        // This is a simplified parser
        let lines = content.components(separatedBy: .newlines)
        var currentStart: Double = 0
        var currentEnd: Double = 0
        var currentText = ""
        
        // Regex for timestamps: 00:00:01.000 --> 00:00:04.000
        let timeRegex = try! NSRegularExpression(pattern: "(\\d{2}:\\d{2}:\\d{2}[.,]\\d{3}) --> (\\d{2}:\\d{2}:\\d{2}[.,]\\d{3})")
        
        for line in lines {
            if let match = timeRegex.firstMatch(in: line, range: NSRange(line.startIndex..., in: line)) {
                if !currentText.isEmpty {
                    entries.append(Entry(startTime: currentStart, endTime: currentEnd, text: currentText.trimmingCharacters(in: .whitespacesAndNewlines)))
                    currentText = ""
                }
                
                let startStr = (line as NSString).substring(with: match.range(at: 1))
                let endStr = (line as NSString).substring(with: match.range(at: 2))
                
                currentStart = parseTime(startStr)
                currentEnd = parseTime(endStr)
            } else if !line.isEmpty && !line.trimmingCharacters(in: .whitespaces).allSatisfy({ $0.isNumber }) && line != "WEBVTT" {
                currentText += line + "\n"
            }
        }
    }
    
    func text(for time: Double) -> String? {
        return entries.first { time >= $0.startTime && time <= $0.endTime }?.text
    }
    
    private func parseTime(_ timeStr: String) -> Double {
        let parts = timeStr.replacingOccurrences(of: ",", with: ".").components(separatedBy: ":")
        guard parts.count == 3 else { return 0 }
        
        let h = Double(parts[0]) ?? 0
        let m = Double(parts[1]) ?? 0
        let s = Double(parts[2]) ?? 0
        
        return h * 3600 + m * 60 + s
    }
}

// MARK: - UIKit Wrappers

struct VideoPlayerView: UIViewRepresentable {
    let player: AVPlayer
    @ObservedObject var playerVM: PlayerViewModel
    
    func makeCoordinator() -> Coordinator {
        Coordinator(playerVM: playerVM)
    }
    
    func makeUIView(context: Context) -> PlayerView {
        print("ðŸŽ¥ VideoPlayerView.makeUIView called")
        let view = PlayerView()
        view.player = player
        
        print("ðŸ”§ Setting up PiP with layer...")
        // Setup PiP with the actual layer being displayed
        DispatchQueue.main.async {
            print("â° DispatchQueue.main.async executing for PiP setup")
            context.coordinator.setupPiP(with: view.playerLayer)
        }
        
        print("âœ… VideoPlayerView.makeUIView completed")
        return view
    }
    
    func updateUIView(_ uiView: PlayerView, context: Context) {
        uiView.player = player
    }
    
    class Coordinator {
        let playerVM: PlayerViewModel
        var pipConfigured = false
        
        init(playerVM: PlayerViewModel) {
            self.playerVM = playerVM
        }
        
        func setupPiP(with layer: AVPlayerLayer) {
            print("ðŸ“ Coordinator.setupPiP called, pipConfigured: \(pipConfigured)")
            guard !pipConfigured else {
                print("âš ï¸ PiP already configured, skipping")
                return
            }
            print("ðŸš€ Calling playerVM.setupPiPWithLayer...")
            playerVM.setupPiPWithLayer(layer)
            pipConfigured = true
            print("âœ… Coordinator.setupPiP completed")
        }
    }
}

class PlayerView: UIView {
    var player: AVPlayer? {
        get { return playerLayer.player }
        set { playerLayer.player = newValue }
    }
    
    var playerLayer: AVPlayerLayer {
        return layer as! AVPlayerLayer
    }
    
    override class var layerClass: AnyClass {
        return AVPlayerLayer.self
    }
    
    override init(frame: CGRect) {
        super.init(frame: frame)
        playerLayer.videoGravity = .resizeAspect
    }
    
    required init?(coder: NSCoder) {
        fatalError("init(coder:) has not been implemented")
    }
}

struct AirPlayView: UIViewRepresentable {
    func makeUIView(context: Context) -> AVRoutePickerView {
        let view = AVRoutePickerView()
        view.activeTintColor = .red
        view.tintColor = .white
        view.prioritizesVideoDevices = true
        return view
    }
    
    func updateUIView(_ uiView: AVRoutePickerView, context: Context) {}
}

// CastButton moved to Views/Components/CastButton.swift

struct CustomProgressBar: View {
    @Binding var value: Double
    var total: Double
    var onEditingChanged: (Bool) -> Void
    
    var body: some View {
        GeometryReader { geometry in
            ZStack(alignment: .leading) {
                // Background Track
                Rectangle()
                    .fill(Color.white.opacity(0.3))
                    .frame(height: 4)
                    .cornerRadius(2)
                
                // Progress Track
                Rectangle()
                    .fill(AppTheme.primaryRed)
                    .frame(width: max(0, min(geometry.size.width, geometry.size.width * (total > 0 ? CGFloat(value / total) : 0))), height: 4)
                    .cornerRadius(2)
                
                // Thumb
                Circle()
                    .fill(AppTheme.primaryRed)
                    .frame(width: 16, height: 16)
                    .scaleEffect(1.2) // Make it slightly larger for better visibility
                    .offset(x: max(0, min(geometry.size.width - 16, geometry.size.width * (total > 0 ? CGFloat(value / total) : 0) - 8)))
            }
            .frame(height: 20) // Touch target height
            .contentShape(Rectangle()) // Ensure the whole area is tappable
            .gesture(
                DragGesture(minimumDistance: 0)
                    .onChanged { value in
                        onEditingChanged(true)
                        let percent = min(max(0, value.location.x / geometry.size.width), 1)
                        self.value = percent * total
                    }
                    .onEnded { _ in
                        onEditingChanged(false)
                    }
            )
        }
        .frame(height: 20)
    }
}
